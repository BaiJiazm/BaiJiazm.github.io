<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Python,爬虫," />










<meta name="description" content="爬虫的基本流程


选取一部分精心挑选的种子URL，将种子URL加入待抓取任务队列。
从待抓取URL队列中取出待抓取的URL，DNS解析得到主机的ip，并将URL对应的网页下载存储进已下载网页库中，将该URL放进已抓取URL队列。
分析提取已下载的网页中的URL，将未抓取过的URL放入待抓取URL队列，从而进入下一个循环。
解析已下载的网页，将需要的数据内容解析出来。
数据持久化，以数据库或其它形">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫的基本流程及反爬虫机制">
<meta property="og:url" content="http://yoursite.com/2018/07/24/Other/爬虫的基本流程及反爬虫机制/index.html">
<meta property="og:site_name" content="BaiJiazm">
<meta property="og:description" content="爬虫的基本流程


选取一部分精心挑选的种子URL，将种子URL加入待抓取任务队列。
从待抓取URL队列中取出待抓取的URL，DNS解析得到主机的ip，并将URL对应的网页下载存储进已下载网页库中，将该URL放进已抓取URL队列。
分析提取已下载的网页中的URL，将未抓取过的URL放入待抓取URL队列，从而进入下一个循环。
解析已下载的网页，将需要的数据内容解析出来。
数据持久化，以数据库或其它形">
<meta property="og:image" content="https://i.imgur.com/ye9VvBW.png">
<meta property="og:image" content="https://i.imgur.com/8NCIf48.png">
<meta property="og:image" content="https://i.imgur.com/LhYgX0L.png">
<meta property="og:image" content="https://i.imgur.com/HepnkrA.jpg">
<meta property="og:image" content="https://i.imgur.com/UZL1hn7.png">
<meta property="og:image" content="https://i.imgur.com/hCAK0uj.png">
<meta property="og:image" content="https://i.imgur.com/v4t2tBA.png">
<meta property="og:image" content="https://i.imgur.com/SUAH4bX.jpg">
<meta property="og:updated_time" content="2018-07-24T16:40:13.751Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="爬虫的基本流程及反爬虫机制">
<meta name="twitter:description" content="爬虫的基本流程


选取一部分精心挑选的种子URL，将种子URL加入待抓取任务队列。
从待抓取URL队列中取出待抓取的URL，DNS解析得到主机的ip，并将URL对应的网页下载存储进已下载网页库中，将该URL放进已抓取URL队列。
分析提取已下载的网页中的URL，将未抓取过的URL放入待抓取URL队列，从而进入下一个循环。
解析已下载的网页，将需要的数据内容解析出来。
数据持久化，以数据库或其它形">
<meta name="twitter:image" content="https://i.imgur.com/ye9VvBW.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"right","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/07/24/Other/爬虫的基本流程及反爬虫机制/"/>





  <title>爬虫的基本流程及反爬虫机制 | BaiJiazm</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">BaiJiazm</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">每一段路都是一种领悟:)</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/24/Other/爬虫的基本流程及反爬虫机制/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="BaiJiazm">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/headPhoto.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BaiJiazm">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">爬虫的基本流程及反爬虫机制</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-24T23:47:51+08:00">
                2018-07-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1>爬虫的基本流程</h1>
<p><img src="https://i.imgur.com/ye9VvBW.png" alt="爬虫的基本流程"></p>
<ul>
<li>选取一部分精心挑选的种子URL，将种子URL加入待抓取任务队列。</li>
<li>从待抓取URL队列中取出待抓取的URL，DNS解析得到主机的ip，并将URL对应的网页下载存储进已下载网页库中，将该URL放进已抓取URL队列。</li>
<li>分析提取已下载的网页中的URL，将未抓取过的URL放入待抓取URL队列，从而进入下一个循环。</li>
<li>解析已下载的网页，将需要的数据内容解析出来。</li>
<li>数据持久化，以数据库或其它形式存储。</li>
</ul>
<h1>一个URL的请求与响应</h1>
<p>爬虫最主要的任务就是发起请求(Request)，然后获取服务器的响应(Response)，遵循HTTP协议。</p>
<p><img src="https://i.imgur.com/8NCIf48.png" alt="请求与响应"></p>
<p><strong>HTTP之请求消息Request</strong></p>
<p>客户端发送一个HTTP请求到服务器的请求消息包括以下格式：</p>
<ul>
<li>请求行（request line）</li>
<li>请求头部（header）</li>
<li>空行</li>
<li>请求数据</li>
</ul>
<p><img src="https://i.imgur.com/LhYgX0L.png" alt="HTTP之请求消息Request"></p>
<p>GET请求样例：</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">GET</span> <span class="string">https://www.tvmao.com/program/CCTV</span> HTTP/1.1</div><div class="line"><span class="attribute">Host</span>: www.tvmao.com</div><div class="line"><span class="attribute">Connection</span>: keep-alive</div><div class="line"><span class="attribute">User-Agent</span>: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.26</div><div class="line"><span class="attribute">Upgrade-Insecure-Requests</span>: 1</div><div class="line"><span class="attribute">Accept</span>: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8</div><div class="line"><span class="attribute">Accept-Encoding</span>: gzip, deflate, br</div><div class="line"><span class="attribute">Accept-Language</span>: zh-CN,zh;q=0.9</div><div class="line"><span class="attribute">Cookie</span>: UM_distinctid=164915db395f1-073fb37f3c265b-4d754111-1fa400-164915db39688f;</div></pre></td></tr></table></figure>
<p><strong>HTTP之响应消息Response</strong></p>
<p>一般情况下，服务器接收并处理客户端发过来的请求后会返回一个HTTP的响应消息。</p>
<p>HTTP响应也由四个部分组成，分别是：</p>
<ul>
<li>状态行</li>
<li>消息报头</li>
<li>空行</li>
<li>响应正文</li>
</ul>
<p><img src="https://i.imgur.com/HepnkrA.jpg" alt="HTTP之响应消息Response"></p>
<p>Response响应样例：</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">HTTP/1.1 <span class="number">200</span> OK</div><div class="line"><span class="attribute">Server</span>: Tengine/2.1.0</div><div class="line"><span class="attribute">Date</span>: Mon, 23 Jul 2018 02:43:33 GMT</div><div class="line"><span class="attribute">Content-Type</span>: text/html;charset=UTF-8</div><div class="line"><span class="attribute">Connection</span>: keep-alive</div><div class="line"><span class="attribute">Vary</span>: Accept-Encoding</div><div class="line"><span class="attribute">Set-Cookie</span>: ASCK=; path=/; expires=Mon, 23-Jul-2018 03:13:33 GMT</div><div class="line"><span class="attribute">Strict-Transport-Security</span>: max-age=15768000</div><div class="line"><span class="attribute">Content-Length</span>: 32143</div><div class="line"></div><div class="line"><span class="undefined">&lt;!doctype html&gt;&lt;head&gt;</span></div><div class="line">&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"/&gt;</div><div class="line">&lt;title&gt;CCTV-1综合节目表,中央电视台综合频道节目表_电视猫&lt;/title&gt;</div><div class="line">...</div><div class="line"></div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure>
<h1>解析网页数据</h1>
<p><a href="http://python.jobbole.com/82633/" target="_blank" rel="external">更多Python爬虫工具</a></p>
<p><strong>Python HTML解析器</strong></p>
<p><img src="https://i.imgur.com/UZL1hn7.png" alt=""></p>
<p><strong>DOM(文档对象模型)树</strong></p>
<p><img src="https://i.imgur.com/hCAK0uj.png" alt=""></p>
<p><strong>重点介绍Beautiful Soup</strong></p>
<p>Beautiful Soup 是一个可以从HTML或XML文件中提取数据的Python库。它能够通过你喜欢的转换器实现惯用的文档导航，查找，修改文档的方式。Beautiful Soup会帮你节省数小时甚至数天的工作时间。</p>
<p><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="external">Beautiful Soup 4.2.0 文档</a></p>
<p>Beautiful Soup 解析html样例：<a href="https://www.tvmao.com/program/CCTV" target="_blank" rel="external">电视猫</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> urllib.request <span class="keyword">as</span> urllib2</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> urllib3</div><div class="line"></div><div class="line"><span class="comment"># 禁用安全请求警告</span></div><div class="line"><span class="keyword">from</span> requests.packages.urllib3.exceptions <span class="keyword">import</span> InsecureRequestWarning</div><div class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)</div><div class="line"></div><div class="line">hrefFile = open(<span class="string">"testHref.txt"</span>, <span class="string">"w"</span>)</div><div class="line">resFile = open(<span class="string">"testRes.txt"</span>, <span class="string">"w"</span>)</div><div class="line"></div><div class="line">proxyHandler = urllib2.ProxyHandler(&#123;</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://115.225.88.99:8118'</span>,</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://118.190.95.43:9001'</span>,</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://111.155.116.207:8123'</span>,</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://122.114.31.177:808'</span>,</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://106.56.102.254:8070'</span>,</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://111.155.116.249:8123'</span>,</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://180.118.240.8:61234'</span>,</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://60.177.225.218:18118'</span></div><div class="line">&#125;)</div><div class="line"></div><div class="line">opener = urllib2.build_opener(proxyHandler)</div><div class="line">urllib2.install_opener(opener)</div><div class="line"></div><div class="line">prefix = <span class="string">'https://www.tvmao.com'</span></div><div class="line"></div><div class="line">todoUrlSet = set()</div><div class="line">doneUrlSet = set()</div><div class="line">channelsSet = set()</div><div class="line"></div><div class="line"><span class="comment"># userAgents是爬虫与反爬虫斗争的第一步</span></div><div class="line">userAgents = [<span class="string">'User-Agent:Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'</span>,</div><div class="line">              <span class="string">'User-Agent:Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'</span>,</div><div class="line">              <span class="string">'User-Agent:Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11'</span>,</div><div class="line">              <span class="string">'User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:57.0) Gecko/20100101 Firefox/57.0'</span>,</div><div class="line">              <span class="string">'User-Agent:Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;InfoPath.2;.NET4.0C;.NET4.0E;.NETCLR2.0.50727;360SE'</span>,</div><div class="line">              <span class="string">'User-Agent:Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0)'</span>,</div><div class="line">              <span class="string">'User-Agent:Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11 '</span>,</div><div class="line">              <span class="string">'User-Agent:Mozilla/5.0(Macintosh;U;IntelMacOSX10_6_8;en-us)AppleWebKit/534.50(KHTML,likeGecko)Version/5.1Safari/534.50 '</span>,</div><div class="line">              <span class="string">'User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.26 Safari/537.36 Core/1.63.5514.400 QQBrowser/10.1.1660.400'</span></div><div class="line">              ]</div><div class="line"></div><div class="line">header = &#123;&#125;</div><div class="line">header[<span class="string">'Accept'</span>] = <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span></div><div class="line">header[<span class="string">'Accept-Encoding'</span>] = <span class="string">'gzip, deflate, br'</span></div><div class="line">header[<span class="string">'Accept-Language'</span>] = <span class="string">'zh-CN,zh;q=0.9'</span></div><div class="line">header[<span class="string">'Connection'</span>] = <span class="string">'keep-alive'</span></div><div class="line">header[<span class="string">'Host'</span>] = <span class="string">'www.tvmao.com'</span></div><div class="line">header[<span class="string">'Origin'</span>] = <span class="string">'https://www.tvmao.com'</span></div><div class="line">header[<span class="string">'Referer'</span>] = <span class="string">'https://www.tvmao.com/program/channels'</span></div><div class="line">header[<span class="string">'User-Agent'</span>] = <span class="string">''</span></div><div class="line">header[<span class="string">'Cache-Control'</span>] = <span class="string">'max-age=0'</span></div><div class="line">header[<span class="string">'Upgrade-Insecure-Requests'</span>] = <span class="string">'1'</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHeaders</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># 随机获取一个headers</span></div><div class="line">    header[<span class="string">'User-Agent'</span>] = random.choice(userAgents)</div><div class="line">    <span class="keyword">return</span> header</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseHtml</span><span class="params">(html)</span>:</span></div><div class="line">    <span class="comment"># print(html)</span></div><div class="line">    div = BeautifulSoup(html,  <span class="string">"lxml"</span>).find_all(<span class="string">'div'</span>, class_=<span class="string">'chlsnav'</span>)</div><div class="line">    divBs = BeautifulSoup(str(div),  <span class="string">"lxml"</span>)</div><div class="line">    <span class="comment"># print(divBs.prettify())</span></div><div class="line"></div><div class="line">    ul = divBs.ul.extract()</div><div class="line">    <span class="comment"># print(BeautifulSoup(str(ul),  "lxml").prettify)</span></div><div class="line">    <span class="comment"># print(BeautifulSoup(str(divBs),  "lxml").prettify)</span></div><div class="line">    <span class="comment"># sys.stdout.flush()</span></div><div class="line">    <span class="comment"># os._exit(0)</span></div><div class="line"></div><div class="line">    <span class="comment"># 寻找可能的新链接页面</span></div><div class="line">    allA = divBs.find_all(<span class="string">'a'</span>)</div><div class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> allA:</div><div class="line">        href = each[<span class="string">'href'</span>]</div><div class="line">        <span class="keyword">if</span> (href <span class="keyword">not</span> <span class="keyword">in</span> doneUrlSet) <span class="keyword">and</span> (href <span class="keyword">not</span> <span class="keyword">in</span> todoUrlSet):</div><div class="line">            print(each.string, href)</div><div class="line">            print(each.string, href, file=hrefFile)</div><div class="line">            todoUrlSet.add(str(href))</div><div class="line"></div><div class="line">    <span class="comment"># 搜集未发现的节目</span></div><div class="line">    <span class="comment"># 查找当前频道仅为了结果的顺序更好一些</span></div><div class="line">    curChn = ul.find_all(<span class="string">'li'</span>, class_=<span class="string">'curchn'</span>)</div><div class="line">    <span class="comment"># print(curChn)</span></div><div class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> curChn:</div><div class="line">        chn = each.string</div><div class="line">        <span class="keyword">if</span> chn <span class="keyword">not</span> <span class="keyword">in</span> channelsSet:</div><div class="line">            print(chn)</div><div class="line">            print(chn, file=resFile)</div><div class="line">            channelsSet.add(chn)</div><div class="line"></div><div class="line">    a = ul.find_all(<span class="string">'a'</span>)</div><div class="line">    <span class="comment"># print(a)</span></div><div class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> a:</div><div class="line">        chn = each.string</div><div class="line">        <span class="keyword">if</span> chn <span class="keyword">not</span> <span class="keyword">in</span> channelsSet:</div><div class="line">            print(chn)</div><div class="line">            print(chn, file=resFile)</div><div class="line">            channelsSet.add(chn)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">spiderGet</span><span class="params">(url)</span>:</span></div><div class="line">    response = requests.get(url=url, headers=getHeaders(), verify=<span class="keyword">False</span>)</div><div class="line">    response.encoding = <span class="string">'utf-8'</span></div><div class="line">    parseHtml(html=response.text)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">spiderOneRoot</span><span class="params">(rootUrl)</span>:</span></div><div class="line">    todoUrlSet.clear()</div><div class="line">    doneUrlSet.clear()</div><div class="line">    todoUrlSet.add(rootUrl)</div><div class="line"></div><div class="line">    failed = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> len(todoUrlSet) &gt; <span class="number">0</span>:</div><div class="line">        postfix = todoUrlSet.pop()</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            doneUrlSet.add(postfix)</div><div class="line">            url = prefix+postfix</div><div class="line">            spiderGet(url)</div><div class="line">            sys.stdout.flush()</div><div class="line">            hrefFile.flush()</div><div class="line">            resFile.flush()</div><div class="line">            failed = <span class="number">0</span></div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            <span class="comment"># print(err)</span></div><div class="line">            todoUrlSet.add(postfix)</div><div class="line">            <span class="comment"># t = random.randint(0, 30)</span></div><div class="line">            <span class="comment"># print('sleep', t, 'sec')</span></div><div class="line">            time.sleep(<span class="number">10</span>)</div><div class="line">            failed = failed+<span class="number">1</span></div><div class="line">            print(<span class="string">'failed'</span>, failed, <span class="string">'time'</span>)</div><div class="line">            <span class="keyword">if</span> failed &gt; <span class="number">120</span>:</div><div class="line">                print(postfix+<span class="string">'failed too much !'</span>)</div><div class="line">                <span class="keyword">return</span></div><div class="line"></div><div class="line"><span class="comment"># spiderOneRoot('/program/CCTV')</span></div><div class="line"><span class="comment"># os._exit(0)</span></div><div class="line"></div><div class="line"></div><div class="line">entryUrl = [</div><div class="line">    <span class="string">'/program/CCTV'</span>,</div><div class="line">    <span class="string">'/program_satellite/AHTV1-w3.html'</span>,</div><div class="line">    <span class="string">'/program_digital/CCTV3D-w3.html'</span>,</div><div class="line">    <span class="string">'/program/TVB'</span>,</div><div class="line">    <span class="string">'/program/AUMEN'</span>,</div><div class="line">    <span class="string">'/program/STARTV'</span>,</div><div class="line">    <span class="string">'/program/AUSTRALIANETWORK'</span>,</div><div class="line">    <span class="string">'/program/HEBEI-HEBEI1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/XIZANGTV-XIZANGTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/ZJTV-ZJTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/GSTV-GSTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/JXTV-JXTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/LNTV-LNTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/CCQTV-CCQTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/SDTV-SDTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/HAINANTV'</span>,</div><div class="line">    <span class="string">'/program/YNTV-YNTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/GUIZOUTV-GUIZOUTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/AHTV-AHTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/AHTV-AHTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/JILIN-JILIN1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/QHTV-QHTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/SCTV-SCTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/NMGTV-NMGTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/HUBEI-HUBEI1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/NXTV-NXTV2-w1.html'</span>,</div><div class="line">    <span class="string">'/program/GUANXI-GUANXI2-w1.html'</span>,</div><div class="line">    <span class="string">'/program/XJTV-XJTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/SHHAI'</span>,</div><div class="line">    <span class="string">'/program/HLJTV-HLJTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/HNTV-HNTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/HNTV-HNTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/SXTV-SXTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/BTV-BTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/GDTV-GDTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/JSTV-JSTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/TJTV-TJTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/HUNANTV-HUNANTV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/SHXITV-SHXITV1-w1.html'</span>,</div><div class="line">    <span class="string">'/program/FJTV-FJTV2-w1.html'</span></div><div class="line">]</div><div class="line"></div><div class="line"><span class="keyword">for</span> url <span class="keyword">in</span> entryUrl:</div><div class="line">    spiderOneRoot(url)</div></pre></td></tr></table></figure>
<h1>存储数据</h1>
<p><img src="https://i.imgur.com/v4t2tBA.png" alt=""></p>
<h1>爬虫的抓取策略</h1>
<p>在爬虫系统中，待抓取URL队列是很重要的一部分。待抓取URL队列中的URL以什么样的顺序排列也是一个很重要的问题，因为这涉及到先抓取那个页面，后抓取哪个页面。而决定这些URL排列顺序的方法，叫做抓取策略。下面重点介绍几种常见的抓取策略：</p>
<p><img src="https://i.imgur.com/SUAH4bX.jpg" alt=""></p>
<p><strong>深度优先策略(DFS)</strong></p>
<p>深度优先策略是指爬虫从某个URL开始，一个链接一个链接的爬取下去，直到处理完了某个链接所在的所有线路，才切换到其它的线路。 此时抓取顺序为：<code>A -&gt; B -&gt; C -&gt; D -&gt; E -&gt; F -&gt; G -&gt; H -&gt; I -&gt; J</code></p>
<p><strong>广度优先策略(BFS)</strong></p>
<p>宽度优先遍历策略的基本思路是，将新下载网页中发现的链接直接插入待抓取URL队列的末尾。也就是指网络爬虫会先抓取起始网页中链接的所有网页，然后再选择其中的一个链接网页，继续抓取在此网页中链接的所有网页。 此时抓取顺序为：<code>A -&gt; B -&gt; E -&gt; G -&gt; H -&gt; I -&gt; C -&gt; F -&gt; J -&gt; D</code></p>
<h1>高效抓取数据（多线程/多进程/分布式爬虫）</h1>
<p>分布式爬取，针对大型爬虫系统的，实现一个分布式的爬虫，主要为以下几个步骤：</p>
<ul>
<li>1、基本的http抓取工具，如scrapy；</li>
<li>2、避免重复抓取网页，如Bloom Filter；</li>
<li>3、维护一个所有集群机器能够有效分享的分布式队列；</li>
<li>4、将分布式队列和Scrapy的结合；</li>
<li>5、后续处理，网页析取(如python-goose)，存储(如Mongodb)。</li>
</ul>
<h1>反爬虫机制与应对策略</h1>
<p>爬虫：使用任何技术手段，批量获取网站信息的一种方式。
反爬虫：使用任何技术手段，阻止别人批量获取自己网站信息的一种方式。</p>
<p>**常见的反爬虫机制：**一般网站从三个方面反爬虫，即请求网站访问时的请求头Headers，用户行为，目标网站的目录和数据加载方式。前两个方面可以说是反爬虫策略中最为常见的，而第三个则是应用ajax（异步加载）的方式加载页面目录或者内容，增大爬虫在对目标网站形成访问之后获取数据的难度。</p>
<h3>0x01 通过Headers反爬虫</h3>
<ul>
<li>
<p><strong>通过Headers中的User-Agent识别爬虫</strong>
从用户请求的Headers反爬虫是最常见的反爬虫策略。由于正常用户访问网站时是通过浏览器访问的，所以目标网站通常会在收到请求时校验Headers中的User-Agent字段，如果不是携带正常的User-Agent信息的请求便无法通过请求。</p>
</li>
<li>
<p><strong>通过Headers中的Refer防止盗链</strong>
盗链是指服务提供商自己不提供服务的内容，利用别人网站的链接去获取别人网站里面的图片或者视频等资源，一部分网站为了防盗链，还会校验请求Headers中的Referer字段。</p>
</li>
</ul>
<h3>0x01 应对策略</h3>
<ul>
<li><strong>构造Headers</strong>
针对这类反爬虫机制，可以直接在自己写的爬虫中添加Headers，将浏览器的User-Agent复制到爬虫的Headers中，或使用User-Agent池。也就是每次发送的时候随机从池中选择不一样的浏览器头信息，防止暴露爬虫身份；另外通过对请求的抓包分析，将Referer值修改为目标网站域名，就能很好的绕过。</li>
</ul>
<h3>0x02 基于用户行为反爬虫</h3>
<ul>
<li>
<p><strong>设置IP访问频率，如果超过一定频率，弹出验证码</strong>
如果输入正确的验证码，则放行，如果没有输入，则拉入禁止一段时间，如果超过禁爬时间，再次出发验证码，则拉入黑名单。当然根据具体的业务，为不同场景设置不同阈值，比如登陆用户和非登陆用户，请求是否含有refer。</p>
</li>
<li>
<p><strong>通过并发识别爬虫</strong>
有些爬虫的并发是很高的，统计并发最高的IP，加入黑名单（或者直接封掉爬虫IP所在C段）</p>
</li>
<li>
<p><strong>请求的时间窗口过滤统计</strong>
爬虫爬取网页的频率都是比较固定的，不像人去访问网页，中间的间隔时间比较无规则，所以我们可以给每个IP地址建立一个时间窗口，记录IP地址最近12次访问时间，每记录一次就滑动一次窗口，比较最近访问时间和当前时间，如果间隔时间很长判断不是爬虫，清除时间窗口，如果间隔不长，就回溯计算指定时间段的访问频率，如果访问频率超过阀值，就转向验证码页面让用户填写验证码。</p>
</li>
<li>
<p><strong>限制单个ip/api token的访问量</strong>
比如15分钟限制访问页面180次，具体标准可参考一些大型网站的公开api，如twitter api，对于抓取用户公开信息的爬虫要格外敏感</p>
</li>
</ul>
<h3>0x02 应对策略</h3>
<ul>
<li>
<p><strong>降低请求频率</strong>
例如每隔一个时间段请求一次或者请求若干次之后sleep一段时间，也可以每次请求后随机间隔几秒再进行下一次请求。由于网站获取到的ip是一个区域网的ip，该ip被区域内的所有人共享，因此这个间隔时间并不需要特别长。</p>
</li>
<li>
<p><strong>使用代理IP池</strong>
使用代理IP池需要大量的IP资源。可以专门写一个在网上抓取可用代理ip的脚本，然后将抓取到的代理ip维护到代理池中供爬虫使用，当然，实际上抓取的ip不论是免费的还是付费的，通常的使用效果都极为一般，如果需要抓取高价值数据的话也可以考虑购买宽带adsl拨号的VPS，如果ip被目标网站被封掉，重新拨号即可。</p>
</li>
</ul>
<h3>0x03 动态页面的反爬虫</h3>
<ul>
<li>
<p><strong>数据通过ajax请求得到或JavaScript生成</strong>
上述的几种情况大多都是出现在静态页面，但是对于动态网页，我们需要爬取的数据是通过ajax请求得到，或者通过JavaScript生成的。</p>
</li>
<li>
<p><strong>ajax请求的所有参数全部加密</strong>
网站把ajax请求的所有参数全部加密了。我们根本没办法构造自己所需要的数据的请求。还有一些严防死守的网站，除了加密ajax参数，它还把一些基本的功能都封装了，全部都是在调用自己的接口，而接口参数都是加密的。</p>
</li>
</ul>
<h3>0x03 应对策略</h3>
<ul>
<li>
<p><strong>模拟ajax请求获取数据</strong>
首先用Firebug或者HttpFox对网络请求进行分析。如果能够找到ajax请求，也能分析出具体的参数和响应的具体含义，我们就能采用上面的方法，直接利用requests或者urllib2模拟ajax请求，对响应的json进行分析得到需要的数据。</p>
</li>
<li>
<p><strong>调用浏览器内核模拟正常人的交互</strong>
通过selenium+phantomJS框架，调用浏览器内核，并利用phantomJS执行js来模拟人为操作以及触发页面中的js脚本。从填写表单到点击按钮再到滚动页面，全部都可以模拟，不考虑具体的请求和响应过程，只是完完整整的把人浏览页面获取数据的过程模拟一遍。用这套框架几乎能绕过大多数的反爬虫，因为它不是在伪装成浏览器来获取数据（上述的通过添加Headers一定程度上就是为了伪装成浏览器），它本身就是浏览器，phantomJS就是一个没有界面的浏览器，只是操控这个浏览器的不是人。</p>
</li>
</ul>
<h3>0x04 其它反爬虫机制-Cookie限制</h3>
<ul>
<li><strong>Cookie限制</strong>
和Headers校验的反爬虫机制类似，当用户向目标网站发送请求时，会再请求数据中携带Cookie，网站通过校验请求信息是否存在Cookie，以及校验Cookie的值来判定发起访问请求的到底是真实的用户还是爬虫，第一次打开网页会生成一个随机cookie，如果再次打开网页这个Cookie不存在，那么再次设置，第三次打开仍然不存在，这就非常有可能是爬虫在工作了。</li>
<li><strong>Cookie校验和Headers的区别</strong>
用户发送的Headers的内容形式是固定的可以被轻易伪造的，Cookie则不然。原因是由于浏览器请求网站访问的过程中所分析得到的Cookie往往都是经过相关的js等过程已经改变了domain的Cookie，假如直接手动修改爬虫携带的Cookie去访问对应的网页，由于携带的Cookie已经是访问之后的domain而不是访问之前的domain，所以是无法成功模拟整个流程的，这种情况必然导致爬虫访问页面失败。</li>
</ul>
<h3>0x04 应对策略</h3>
<ul>
<li><strong>分析Cookie</strong>
分析Cookie，可能会携带大量的随机哈希字符串，或者不同时间戳组合的字符串，并且会根据每次访问更新domain的值。分析过程：首先要在对目标网站抓包分析时，必须先清空浏览器的Cookie，然后在初次访问时，观察浏览器在完成访问的过程中的请求细节（通常会在这一过程中发生若干次301/302转跳，每次转跳网站返回不同的Cookie给浏览器然后在最后一次转跳中请求成功）。在抓包完成对请求细节的分析之后，再在爬虫上模拟这一转跳过程，然后截取Cookie作为爬虫自身携带的Cookie，这样就能够绕过Cookie的限制完成对目标网站的访问了。</li>
</ul>
<h3>0x05 其它反爬虫机制-验证码限制</h3>
<ul>
<li>
<p>验证码（CAPTCHA）是“Completely Automated Public Turing test to tell Computers and Humans Apart”（全自动区分计算机和人类的图灵测试）的缩写，是一种区分用户是计算机还是人的公共全自动程序。人类有着一种天赋，可以很轻松的从一段图片中识别出文字和数字，而机器却不能。</p>
</li>
<li>
<p><strong>数字字母验证码</strong>
这类验证码优点是生成简单，大部分语言都自带图形库，在加入一点扭曲和噪点，基本可以解决掉初级爬虫工程师和暴力破解的脚本小子。缺点当然也显而易见，对于cnn代码只用写10行的今天，这些验证码只要有足够的标注数据，破解起来简直是轻而易举。</p>
</li>
<li>
<p><strong>中文验证码</strong>
比如知乎采用过的验证码选择倒立的中文以及网易邮箱类的验证码（标记文字位置）。这类验证码一般来很少有公用的代码，因此编写起来麻烦。不过也正因为每一家采用的都不一样，在加上中文庞大的汉字库，确实给机器识别带来的比较大的挑战，如果配合好字体和扭曲，确实可以有不错的效果。</p>
</li>
<li>
<p><strong>极验验证</strong>
极验的v2版验证体系破解难度甚至比不过数字字母验证码来的复杂，唯一的优势就是现在大部分打码平台不支持。图片识别上直接对比像素就可以识别位置，唯一难点的移动轨迹，但用轨迹做分类人类和机器间的特征并不那么明显，加上网页中采集轨迹的准确性较差，因此做一些简单的模拟就可以轻松躲过轨迹识别。</p>
</li>
<li>
<p><strong>其它验证类型</strong>
比如12306这类图片验证，这种反爬虫要求较高，需要强大的图片库。其它还有算术验证、成语验证等等，发爬虫通过难度不是很高。</p>
</li>
</ul>
<h3>0x05 应对策略</h3>
<ul>
<li>
<p><strong>打码平台</strong>
最常用，最简单的识别，一般字母文字1分一次，中文识别略贵，计算题可能5分，不支持极验这类。</p>
</li>
<li>
<p><strong>OCR库</strong>
传统的ocr采用先切割再识别的方案，对于新型的验证码已经很难做了。</p>
</li>
<li>
<p><strong>机器学习</strong>
端到端数字字母识别神器，根据识别难度和长度不同，对标注数据的需求量不一样，当然图片预处理也稍微有些区别。一般简单常见的识别可以直接从网上找代码。</p>
</li>
</ul>
<h1>参考文档</h1>
<ul>
<li><a href="https://www.jianshu.com/p/80e25cb1d81a" target="_blank" rel="external">关于HTTP协议，一篇就够了</a></li>
<li><a href="https://blog.csdn.net/u012662731/article/details/78537432" target="_blank" rel="external">Python3网络爬虫快速入门实战解析</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1032918" target="_blank" rel="external">反爬虫机制和破解方法汇总</a></li>
<li><a href="http://bigsec.com/bigsec-news/anan-16825-Antireptile-zonghe" target="_blank" rel="external">反爬虫思路与解决办法</a></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
            <a href="/tags/爬虫/" rel="tag"># 爬虫</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/21/Other/并行计算 cuda/" rel="next" title="并行计算 cuda">
                <i class="fa fa-chevron-left"></i> 并行计算 cuda
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/21/Major/检测图存在环算法/" rel="prev" title="检测图存在环方法">
                检测图存在环方法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/headPhoto.png"
                alt="BaiJiazm" />
            
              <p class="site-author-name" itemprop="name">BaiJiazm</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">80</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">37</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/BaiJiazm" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:b110011@qq.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">爬虫的基本流程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">一个URL的请求与响应</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">解析网页数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">存储数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">爬虫的抓取策略</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">高效抓取数据（多线程/多进程/分布式爬虫）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">反爬虫机制与应对策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.1.</span> <span class="nav-text">0x01 通过Headers反爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.2.</span> <span class="nav-text">0x01 应对策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.3.</span> <span class="nav-text">0x02 基于用户行为反爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.4.</span> <span class="nav-text">0x02 应对策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.5.</span> <span class="nav-text">0x03 动态页面的反爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.6.</span> <span class="nav-text">0x03 应对策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.7.</span> <span class="nav-text">0x04 其它反爬虫机制-Cookie限制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.8.</span> <span class="nav-text">0x04 应对策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.9.</span> <span class="nav-text">0x05 其它反爬虫机制-验证码限制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">7.0.10.</span> <span class="nav-text">0x05 应对策略</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">8.</span> <span class="nav-text">参考文档</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">BaiJiazm</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  
  

  

  

  

</body>
</html>
